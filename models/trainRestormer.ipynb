{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mamo_alegua/anaconda3/envs/anton2/lib/python3.9/site-packages/parallelproj/backend.py:18: UserWarning: The numpy.array_api submodule is still experimental. See NEP 47.\n",
      "  from numpy.array_api._array_object import Array\n",
      "/home/mamo_alegua/anaconda3/envs/anton2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/mamo_alegua/anaconda3/envs/anton2/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/mamo_alegua/anaconda3/envs/anton2/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c105ErrorC2ENS_14SourceLocationESs\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import parallelproj\n",
    "import torch\n",
    "import numpy as np\n",
    "from odl.contrib import fom\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "from array_api_compat import to_device\n",
    "import array_api_compat.torch as xp\n",
    "from utils.data import *\n",
    "from utils.geometry import *\n",
    "from torch.nn.parallel import DataParallel as DP\n",
    "\n",
    "dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mamo_alegua/anaconda3/envs/anton2/lib/python3.9/site-packages/parallelproj/pet_scanners.py:309: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  side = inds // self.num_lor_endpoints_per_side\n",
      "/home/mamo_alegua/anaconda3/envs/anton2/lib/python3.9/site-packages/parallelproj/pet_lors.py:258: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  self.xp.concat((self.xp.arange(m) // 2, self.xp.asarray([n // 2])))\n",
      "/home/mamo_alegua/anaconda3/envs/anton2/lib/python3.9/site-packages/parallelproj/pet_lors.py:262: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  self.xp.concat((self.xp.asarray([-1]), -((self.xp.arange(m) + 4) // 2)))\n"
     ]
    }
   ],
   "source": [
    "proj = get_minipet_projector(dev,num_rings=2)\n",
    "num_train = 5250\n",
    "batch_size = 6\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(RandomEllipsoids(num_ellipsoids=np.random.poisson(10), diag=200, proj=proj, num_images=num_train, axes_scale=0.3),\n",
    "                                            batch_size, shuffle=True, num_workers=9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 23,248,584\n"
     ]
    }
   ],
   "source": [
    "from models.restormerLPD import *\n",
    "\n",
    "num_epochs = 150\n",
    "n_iter = 3\n",
    "normalisation=(proj.norm(xp,\"cuda\"))**2\n",
    "model = DP(LPD(n_iter, proj, normalisation, return_all=False), device_ids=[1,2,3,4,6,7])\n",
    "\n",
    "model.to(dev)\n",
    "print(\"Number of parameters: {:,}\".format(sum(p.numel() for p in model.parameters())))\n",
    "\n",
    "for m in model.modules():\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "        nn.init.normal_(m.weight, mean=0.0, std=0.02)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "no_decay = []\n",
    "decay = []\n",
    "for name, param in model.named_parameters():\n",
    "    if 'weight' in name and 'batchnorm' and 'layernorm' and 'relative_bias_table' not in name:\n",
    "        decay.append(param)\n",
    "    else:\n",
    "        no_decay.append(param)\n",
    "\n",
    "optimizer = optim.AdamW([\n",
    "    {'params': decay, 'weight_decay': 0.01},\n",
    "    {'params': no_decay, 'weight_decay': 0}\n",
    "], lr=1e-4)\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "lr_scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=5e-4,\n",
    "                                             steps_per_epoch=len(train_loader), epochs=num_epochs)\n",
    "\n",
    "start_epoch = 0\n",
    "\n",
    "scanner = None\n",
    "lor_desc = None\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cp = torch.load(\"/home/mamo_alegua/anaconda3/LPDTransformer/\"+\"3iterUnetCA50\")\n",
    "#model.module.load_state_dict(cp['model'])\n",
    "#optimizer.load_state_dict(cp['optimizer'])\n",
    "#lr_scheduler.load_state_dict(cp['lr_scheduler'])\n",
    "#start_epoch = cp['epoch'] + 1\n",
    "#del cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "from torch.cuda.amp import GradScaler\n",
    "scaler = GradScaler(growth_interval=10)\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    running_loss = 0.0\n",
    "    ssim_list = []\n",
    "    psnr_list = []\n",
    "    for idx, images in enumerate(train_loader, 0):\n",
    "        images = to_device(images, dev)\n",
    "        with torch.autocast(device_type=\"cuda\"):\n",
    "            trainSino = generate_data(blur_image(images, kernel_size=5, sigma=2.0), proj, noise_level=np.random.uniform(0.1,1.2))\n",
    "        \n",
    "            for param in model.parameters():\n",
    "                param.grad = None\n",
    "                \n",
    "            outputs = model(trainSino)\n",
    "\n",
    "            loss_value = loss_function(outputs, images)\n",
    "        \n",
    "        images = images.to('cpu').numpy()\n",
    "        del trainSino\n",
    "\n",
    "        scaler.scale(loss_value).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scale = scaler.get_scale()\n",
    "        scaler.update()\n",
    "\n",
    "        skip_lr_sched = (scale > scaler.get_scale())\n",
    "        if not skip_lr_sched:\n",
    "            lr_scheduler.step()\n",
    "\n",
    "        running_loss += loss_value.item()\n",
    "\n",
    "        for j in range(outputs.shape[0]):\n",
    "            for i in range(proj.in_shape[1]):\n",
    "                psnr_list.append(fom.psnr(outputs[j,:,i,:].detach().cpu().numpy(),images[j,:,i,:]))\n",
    "                ssim_list.append(fom.ssim(outputs[j,:,i,:].detach().cpu(),images[j,:,i,:]))\n",
    "\n",
    "    running_loss /= len(train_loader)\n",
    "\n",
    "    psnr_value = np.mean(psnr_list)\n",
    "    ssim_value = np.mean(ssim_list)\n",
    "\n",
    "    print(\"{}/{} - loss {:.3f}; PSNR {:.3f}; SSIM {:.3f}\".format(\n",
    "        epoch+1, num_epochs, running_loss, psnr_value, ssim_value)) \n",
    "    \n",
    "    if (epoch+1) % 25 == 0:\n",
    "        print(\"Saving Checkpoint...\")\n",
    "        cp = {'epoch': epoch,'model': model.module.state_dict(), 'optimizer': optimizer.state_dict(), 'lr_scheduler': lr_scheduler.state_dict()}\n",
    "        torch.save(cp, \"/home/mamo_alegua/anaconda3/LPDTransformer/\"+\"3iterRestormer\"+str(epoch+1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anton2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
