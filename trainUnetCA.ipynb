{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mamo_alegua/anaconda3/envs/anton2/lib/python3.9/site-packages/parallelproj/backend.py:18: UserWarning: The numpy.array_api submodule is still experimental. See NEP 47.\n",
      "  from numpy.array_api._array_object import Array\n",
      "/home/mamo_alegua/anaconda3/envs/anton2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/mamo_alegua/anaconda3/envs/anton2/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/mamo_alegua/anaconda3/envs/anton2/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c105ErrorC2ENS_14SourceLocationESs\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import parallelproj\n",
    "import torch\n",
    "import numpy as np\n",
    "from odl.contrib import fom\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "from array_api_compat import to_device\n",
    "import array_api_compat.torch as xp\n",
    "from data import *\n",
    "from geometry import *\n",
    "from torch.nn.parallel import DataParallel as DP\n",
    "\n",
    "dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mamo_alegua/anaconda3/envs/anton2/lib/python3.9/site-packages/parallelproj/pet_scanners.py:309: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  side = inds // self.num_lor_endpoints_per_side\n",
      "/home/mamo_alegua/anaconda3/envs/anton2/lib/python3.9/site-packages/parallelproj/pet_lors.py:258: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  self.xp.concat((self.xp.arange(m) // 2, self.xp.asarray([n // 2])))\n",
      "/home/mamo_alegua/anaconda3/envs/anton2/lib/python3.9/site-packages/parallelproj/pet_lors.py:262: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  self.xp.concat((self.xp.asarray([-1]), -((self.xp.arange(m) + 4) // 2)))\n"
     ]
    }
   ],
   "source": [
    "proj = get_minipet_projector(dev,num_rings=21)\n",
    "num_train = 500\n",
    "batch_size = 6\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(RandomEllipsoids(num_ellipsoids=np.random.poisson(10), diag=200, proj=proj, num_images=num_train, axes_scale=0.3, dim=3),\n",
    "                                            batch_size, shuffle=True, num_workers=9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 19,596,686\n"
     ]
    }
   ],
   "source": [
    "from lpdUnetCrossAttention3 import *\n",
    "\n",
    "num_epochs = 150\n",
    "n_iter = 3\n",
    "normalisation=(proj.norm(xp,\"cuda\"))**2\n",
    "model = DP(LPD(n_iter, proj, normalisation,indices=patch_sinogram(proj, patch_size=(7,7), return_values=True)), device_ids=[1,2,3,4,6,7])\n",
    "\n",
    "model.to(dev)\n",
    "print(\"Number of parameters: {:,}\".format(sum(p.numel() for p in model.parameters())))\n",
    "\n",
    "for m in model.modules():\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "        nn.init.normal_(m.weight, mean=0.0, std=0.02)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "no_decay = []\n",
    "decay = []\n",
    "for name, param in model.named_parameters():\n",
    "    if 'weight' in name and 'batchnorm' and 'layernorm' and 'relative_bias_table' not in name:\n",
    "        decay.append(param)\n",
    "    else:\n",
    "        no_decay.append(param)\n",
    "\n",
    "optimizer = optim.AdamW([\n",
    "    {'params': decay, 'weight_decay': 0.01},\n",
    "    {'params': no_decay, 'weight_decay': 0}\n",
    "], lr=1e-4)\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "lr_scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=5e-4,\n",
    "                                             steps_per_epoch=len(train_loader), epochs=num_epochs)\n",
    "\n",
    "start_epoch = 0\n",
    "\n",
    "scanner = None\n",
    "lor_desc = None\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cp = torch.load(\"/home/mamo_alegua/anaconda3/LPDTransformer/\"+\"3iterUnetCA125\")\n",
    "#model.module.load_state_dict(cp['model'])\n",
    "#optimizer.load_state_dict(cp['optimizer'])\n",
    "#lr_scheduler.load_state_dict(cp['lr_scheduler'])\n",
    "#start_epoch = cp['epoch'] + 1\n",
    "#del cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/150 - loss 0.729; PSNR -inf; SSIM 0.000\n",
      "2/150 - loss 0.362; PSNR 3.036; SSIM 0.002\n",
      "3/150 - loss 0.191; PSNR 5.795; SSIM 0.007\n",
      "4/150 - loss 0.092; PSNR 8.991; SSIM 0.016\n",
      "5/150 - loss 0.038; PSNR -inf; SSIM 0.037\n",
      "6/150 - loss 0.014; PSNR -inf; SSIM 0.083\n",
      "7/150 - loss 0.008; PSNR -inf; SSIM 0.154\n",
      "8/150 - loss 0.006; PSNR -inf; SSIM 0.214\n",
      "9/150 - loss 0.005; PSNR -inf; SSIM 0.250\n",
      "10/150 - loss 0.004; PSNR -inf; SSIM 0.275\n",
      "11/150 - loss 0.004; PSNR 22.780; SSIM 0.305\n",
      "12/150 - loss 0.004; PSNR 23.067; SSIM 0.327\n",
      "13/150 - loss 0.004; PSNR -inf; SSIM 0.337\n",
      "14/150 - loss 0.003; PSNR -inf; SSIM 0.381\n",
      "15/150 - loss 0.003; PSNR -inf; SSIM 0.396\n",
      "16/150 - loss 0.003; PSNR 24.142; SSIM 0.400\n",
      "17/150 - loss 0.003; PSNR 24.478; SSIM 0.426\n",
      "18/150 - loss 0.002; PSNR 24.860; SSIM 0.455\n",
      "19/150 - loss 0.003; PSNR -inf; SSIM 0.466\n",
      "20/150 - loss 0.002; PSNR 25.047; SSIM 0.483\n",
      "21/150 - loss 0.002; PSNR 25.397; SSIM 0.496\n",
      "22/150 - loss 0.002; PSNR -inf; SSIM 0.462\n",
      "23/150 - loss 0.002; PSNR -inf; SSIM 0.517\n",
      "24/150 - loss 0.002; PSNR -inf; SSIM 0.531\n",
      "25/150 - loss 0.002; PSNR 25.276; SSIM 0.484\n",
      "Saving Checkpoint...\n",
      "26/150 - loss 0.002; PSNR 25.911; SSIM 0.550\n",
      "27/150 - loss 0.002; PSNR 25.784; SSIM 0.553\n",
      "28/150 - loss 0.002; PSNR -inf; SSIM 0.558\n",
      "29/150 - loss 0.002; PSNR 25.992; SSIM 0.579\n",
      "30/150 - loss 0.002; PSNR -inf; SSIM 0.587\n",
      "31/150 - loss 0.002; PSNR 26.040; SSIM 0.572\n",
      "32/150 - loss 0.002; PSNR 26.178; SSIM 0.592\n",
      "33/150 - loss 0.002; PSNR -inf; SSIM 0.593\n",
      "34/150 - loss 0.002; PSNR 26.585; SSIM 0.627\n",
      "35/150 - loss 0.003; PSNR 25.235; SSIM 0.525\n",
      "36/150 - loss 0.003; PSNR -inf; SSIM 0.438\n",
      "37/150 - loss 0.002; PSNR -inf; SSIM 0.566\n",
      "38/150 - loss 0.002; PSNR -inf; SSIM 0.549\n",
      "39/150 - loss 0.002; PSNR -inf; SSIM 0.579\n",
      "40/150 - loss 0.002; PSNR 25.278; SSIM 0.496\n",
      "41/150 - loss 0.002; PSNR -inf; SSIM 0.570\n",
      "42/150 - loss 0.002; PSNR -inf; SSIM 0.595\n",
      "43/150 - loss 0.002; PSNR 26.387; SSIM 0.610\n",
      "44/150 - loss 0.002; PSNR -inf; SSIM 0.666\n",
      "45/150 - loss 0.002; PSNR -inf; SSIM 0.679\n",
      "46/150 - loss 0.002; PSNR -inf; SSIM 0.692\n",
      "47/150 - loss 0.005; PSNR -inf; SSIM 0.400\n",
      "48/150 - loss 0.003; PSNR 24.212; SSIM 0.404\n",
      "49/150 - loss 0.003; PSNR 24.528; SSIM 0.424\n",
      "50/150 - loss 0.002; PSNR 25.557; SSIM 0.508\n",
      "Saving Checkpoint...\n",
      "51/150 - loss 0.002; PSNR -inf; SSIM 0.528\n",
      "52/150 - loss 0.002; PSNR 26.218; SSIM 0.571\n",
      "53/150 - loss 0.002; PSNR -inf; SSIM 0.560\n",
      "54/150 - loss 0.002; PSNR 26.356; SSIM 0.604\n",
      "55/150 - loss 0.002; PSNR 26.532; SSIM 0.617\n",
      "56/150 - loss 0.003; PSNR -inf; SSIM 0.551\n",
      "57/150 - loss 0.003; PSNR 24.670; SSIM 0.451\n",
      "58/150 - loss 0.002; PSNR 26.221; SSIM 0.584\n",
      "59/150 - loss 0.002; PSNR 26.676; SSIM 0.638\n",
      "60/150 - loss 0.002; PSNR 26.541; SSIM 0.615\n",
      "61/150 - loss 0.002; PSNR 26.852; SSIM 0.643\n",
      "62/150 - loss 0.002; PSNR -inf; SSIM 0.673\n",
      "63/150 - loss 0.002; PSNR -inf; SSIM 0.650\n",
      "64/150 - loss 0.002; PSNR -inf; SSIM 0.681\n",
      "65/150 - loss 0.002; PSNR 26.957; SSIM 0.672\n",
      "66/150 - loss 0.002; PSNR -inf; SSIM 0.691\n",
      "67/150 - loss 0.002; PSNR -inf; SSIM 0.688\n",
      "68/150 - loss 0.002; PSNR 27.130; SSIM 0.670\n",
      "69/150 - loss 0.001; PSNR -inf; SSIM 0.686\n",
      "70/150 - loss 0.002; PSNR -inf; SSIM 0.669\n",
      "71/150 - loss 0.002; PSNR -inf; SSIM 0.654\n",
      "72/150 - loss 0.002; PSNR -inf; SSIM 0.687\n",
      "73/150 - loss 0.002; PSNR -inf; SSIM 0.650\n",
      "74/150 - loss 0.002; PSNR -inf; SSIM 0.682\n",
      "75/150 - loss 0.002; PSNR 27.222; SSIM 0.686\n",
      "Saving Checkpoint...\n",
      "76/150 - loss 0.001; PSNR 27.416; SSIM 0.714\n",
      "77/150 - loss 0.002; PSNR -inf; SSIM 0.687\n",
      "78/150 - loss 0.002; PSNR -inf; SSIM 0.680\n",
      "79/150 - loss 0.001; PSNR -inf; SSIM 0.712\n",
      "80/150 - loss 0.001; PSNR 27.519; SSIM 0.718\n",
      "81/150 - loss 0.001; PSNR -inf; SSIM 0.720\n",
      "82/150 - loss 0.001; PSNR 27.546; SSIM 0.713\n",
      "83/150 - loss 0.001; PSNR 27.316; SSIM 0.686\n",
      "84/150 - loss 0.001; PSNR 27.519; SSIM 0.707\n",
      "85/150 - loss 0.001; PSNR 27.513; SSIM 0.699\n",
      "86/150 - loss 0.001; PSNR -inf; SSIM 0.716\n",
      "87/150 - loss 0.001; PSNR 27.527; SSIM 0.740\n",
      "88/150 - loss 0.001; PSNR 27.564; SSIM 0.722\n",
      "89/150 - loss 0.001; PSNR 27.765; SSIM 0.738\n",
      "90/150 - loss 0.001; PSNR -inf; SSIM 0.758\n",
      "91/150 - loss 0.001; PSNR 27.660; SSIM 0.744\n",
      "92/150 - loss 0.002; PSNR 26.675; SSIM 0.635\n",
      "93/150 - loss 0.002; PSNR -inf; SSIM 0.532\n",
      "94/150 - loss 0.002; PSNR -inf; SSIM 0.653\n",
      "95/150 - loss 0.001; PSNR 27.483; SSIM 0.712\n",
      "96/150 - loss 0.001; PSNR -inf; SSIM 0.675\n",
      "97/150 - loss 0.001; PSNR 27.577; SSIM 0.720\n",
      "98/150 - loss 0.001; PSNR -inf; SSIM 0.724\n",
      "99/150 - loss 0.001; PSNR -inf; SSIM 0.748\n",
      "100/150 - loss 0.001; PSNR -inf; SSIM 0.759\n",
      "Saving Checkpoint...\n",
      "101/150 - loss 0.001; PSNR -inf; SSIM 0.751\n",
      "102/150 - loss 0.001; PSNR 27.747; SSIM 0.730\n",
      "103/150 - loss 0.001; PSNR -inf; SSIM 0.744\n",
      "104/150 - loss 0.001; PSNR 27.895; SSIM 0.746\n",
      "105/150 - loss 0.001; PSNR 27.954; SSIM 0.758\n",
      "106/150 - loss 0.001; PSNR -inf; SSIM 0.788\n",
      "107/150 - loss 0.001; PSNR 28.070; SSIM 0.774\n",
      "108/150 - loss 0.001; PSNR 28.006; SSIM 0.768\n",
      "109/150 - loss 0.001; PSNR 28.070; SSIM 0.774\n",
      "110/150 - loss 0.001; PSNR 27.973; SSIM 0.766\n",
      "111/150 - loss 0.001; PSNR -inf; SSIM 0.770\n",
      "112/150 - loss 0.001; PSNR 28.078; SSIM 0.771\n",
      "113/150 - loss 0.001; PSNR -inf; SSIM 0.785\n",
      "114/150 - loss 0.001; PSNR -inf; SSIM 0.749\n",
      "115/150 - loss 0.001; PSNR -inf; SSIM 0.779\n",
      "116/150 - loss 0.001; PSNR -inf; SSIM 0.786\n",
      "117/150 - loss 0.001; PSNR -inf; SSIM 0.775\n",
      "118/150 - loss 0.001; PSNR 28.119; SSIM 0.782\n",
      "119/150 - loss 0.001; PSNR 28.250; SSIM 0.793\n",
      "120/150 - loss 0.001; PSNR 28.208; SSIM 0.799\n",
      "121/150 - loss 0.001; PSNR 28.347; SSIM 0.800\n",
      "122/150 - loss 0.001; PSNR 28.220; SSIM 0.798\n",
      "123/150 - loss 0.001; PSNR -inf; SSIM 0.802\n",
      "124/150 - loss 0.001; PSNR 28.326; SSIM 0.800\n",
      "125/150 - loss 0.001; PSNR 28.335; SSIM 0.798\n",
      "Saving Checkpoint...\n",
      "126/150 - loss 0.001; PSNR 28.295; SSIM 0.800\n",
      "127/150 - loss 0.001; PSNR -inf; SSIM 0.811\n",
      "128/150 - loss 0.001; PSNR -inf; SSIM 0.809\n",
      "129/150 - loss 0.001; PSNR 28.443; SSIM 0.816\n",
      "130/150 - loss 0.001; PSNR -inf; SSIM 0.817\n",
      "131/150 - loss 0.001; PSNR 28.230; SSIM 0.810\n",
      "132/150 - loss 0.001; PSNR -inf; SSIM 0.822\n",
      "133/150 - loss 0.001; PSNR -inf; SSIM 0.819\n"
     ]
    }
   ],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "from torch.cuda.amp import GradScaler\n",
    "scaler = GradScaler(growth_interval=100)\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    running_loss = 0.0\n",
    "    ssim_list = []\n",
    "    psnr_list = []\n",
    "    for idx, images in enumerate(train_loader, 0):\n",
    "        images = to_device(images, dev)\n",
    "        with torch.autocast(device_type=\"cuda\"):\n",
    "            trainSino = generate_data(blur_image(images, kernel_size=5, sigma=2.0), proj, noise_level=np.random.uniform(0.1,1.2))\n",
    "        \n",
    "            for param in model.parameters():\n",
    "                param.grad = None\n",
    "                \n",
    "            outputs = model(trainSino)\n",
    "\n",
    "            loss_value = loss_function(outputs, images)\n",
    "        \n",
    "        images = images.to('cpu').numpy()\n",
    "        del trainSino\n",
    "\n",
    "        scaler.scale(loss_value).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scale = scaler.get_scale()\n",
    "        scaler.update()\n",
    "\n",
    "        skip_lr_sched = (scale > scaler.get_scale())\n",
    "        if not skip_lr_sched:\n",
    "            lr_scheduler.step()\n",
    "\n",
    "        running_loss += loss_value.item()\n",
    "\n",
    "        for j in range(outputs.shape[0]):\n",
    "            for i in range(proj.in_shape[1]):\n",
    "                psnr_list.append(fom.psnr(outputs[j,:,i,:].detach().cpu().numpy(),images[j,:,i,:]))\n",
    "                ssim_list.append(fom.ssim(outputs[j,:,i,:].detach().cpu(),images[j,:,i,:]))\n",
    "\n",
    "    running_loss /= len(train_loader)\n",
    "\n",
    "    psnr_value = np.mean(psnr_list)\n",
    "    ssim_value = np.mean(ssim_list)\n",
    "\n",
    "    print(\"{}/{} - loss {:.3f}; PSNR {:.3f}; SSIM {:.3f}\".format(\n",
    "        epoch+1, num_epochs, running_loss, psnr_value, ssim_value))\n",
    "    \n",
    "    if (epoch+1) % 25 == 0:\n",
    "        print(\"Saving Checkpoint...\")\n",
    "        cp = {'epoch': epoch,'model': model.module.state_dict(), 'optimizer': optimizer.state_dict(), 'lr_scheduler': lr_scheduler.state_dict()}\n",
    "        torch.save(cp, \"/home/mamo_alegua/anaconda3/LPDTransformer/\"+\"3iterUnetV2CA\"+str(epoch+1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anton2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
